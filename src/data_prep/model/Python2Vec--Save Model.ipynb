{"nbformat_minor": 0, "cells": [{"source": "# Load the Data", "cell_type": "markdown", "metadata": {}}, {"execution_count": 2, "cell_type": "code", "source": "code_lines = sqlCtx.read.json(\n    # Put the location to your data here\n    'git_repos/*.json.gz',\n)\ncode_lines = code_lines.repartition(300)", "outputs": [], "metadata": {"collapsed": false, "trusted": true}}, {"source": "# Create the Python2Vec Model", "cell_type": "markdown", "metadata": {}}, {"execution_count": 3, "cell_type": "code", "source": "import re\n\ndef split_code(input):\n    strs = ' '.join(input)\n    patt = re.compile(ur\"[\\w]+\", re.UNICODE) \n    return patt.findall(strs)", "outputs": [], "metadata": {"collapsed": true, "trusted": true}}, {"execution_count": 4, "cell_type": "code", "source": "words = code_lines\\\n    .map(\n        lambda (\n            author,\n            author_mail,\n            author_time,\n            author_timezone,\n            comment,\n            commit_id,\n            committer,\n            committer_mail,\n            committer_time,\n            committer_timezone,\n            filename,\n            line,\n            line_num,\n            repo_name,\n            ):\n            (line.split())\n    )\\\n    .map(lambda line: [f.lower() for f in line])\\\n    .map(lambda line: split_code(line))\\\n    .filter(lambda line: line != [])", "outputs": [], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": 5, "cell_type": "code", "source": "from pyspark.mllib.feature import Word2Vec\n\nword2vec = Word2Vec()\nword2vec.setMinCount(25) # Default 100\nword2vec.setVectorSize(50) # Default 100\nmodel = word2vec.fit(words)", "outputs": [], "metadata": {"scrolled": false, "collapsed": false, "trusted": true}}, {"source": "# Save the model", "cell_type": "markdown", "metadata": {}}, {"source": "We save two copies: One JSON version that can be passed arround to other people, and a pickle version that you can use to load the model on your own machine.", "cell_type": "markdown", "metadata": {}}, {"execution_count": 7, "cell_type": "code", "source": "import json\n\nmodel_dict = {k:list(v) for k,v in dict(model.getVectors()).iteritems()}\n\nwith open(\"/tmp/py2vec_model.json\", \"w\") as f:\n    json.dump(model_dict, f, indent=4)", "outputs": [], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": 15, "cell_type": "code", "source": "import cPickle as pickle\nimport numpy as np\n\nmodel_dict = {k:np.array(list(v)) for k,v in dict(model.getVectors()).iteritems()}\n\nwith open(\"/tmp/py2vec_model.pkl\", \"wb\") as f:\n    pickle.dump(model_dict, f)", "outputs": [], "metadata": {"collapsed": false, "trusted": true}}, {"source": "# Load the model", "cell_type": "markdown", "metadata": {}}, {"execution_count": 16, "cell_type": "code", "source": "with open(\"/tmp/py2vec_model.pkl\", \"rb\") as f:\n    loaded_model = pickle.load(f)", "outputs": [], "metadata": {"scrolled": true, "collapsed": false, "trusted": true}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "Python 2", "name": "python2", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "2.7.10", "name": "python", "file_extension": ".py", "pygments_lexer": "ipython2", "codemirror_mode": {"version": 2, "name": "ipython"}}}}